{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\alice\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\alice\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import string\n",
    "\n",
    "import datetime\n",
    "from textblob import TextBlob #for polarity and sentiment analysis\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize  \n",
    "from nltk.corpus import stopwords\n",
    "import swifter\n",
    "from pprint import pprint\n",
    "\n",
    "import gensim\n",
    "from gensim.summarization import summarize, keywords\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.stem.porter import *\n",
    "nltk.download('wordnet')\n",
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(df):\n",
    "    replace_char = [\"[\", \"]\", \"'\", \"EDT\", \"EST\", \" views\", '\"']\n",
    "    for i in df.columns:\n",
    "        for r in replace_char:\n",
    "            df[i] = df[i].str.replace(r, '')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.read_csv(\"data_7k_haley.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7477"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "7\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "for i in df.columns:\n",
    "    print(df[i].isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = df[3736:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>link</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>view</th>\n",
       "      <th>topic</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3814</th>\n",
       "      <td>https://www.forbes.com/sites/lisettevoytko/202...</td>\n",
       "      <td>Report: Japan Has No Backup Plan If Olympic Ga...</td>\n",
       "      <td>People wearing masks sit in front of a countdo...</td>\n",
       "      <td>6,970</td>\n",
       "      <td>Business</td>\n",
       "      <td>Feb 28, 2020, 08:59am</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3815</th>\n",
       "      <td>https://www.forbes.com/sites/lisettevoytko/202...</td>\n",
       "      <td>WHO Raises Coronavirus Threat To ‘Very High’\\u...</td>\n",
       "      <td>Workers wearing protective gears spray disinfe...</td>\n",
       "      <td>9,653</td>\n",
       "      <td>Business</td>\n",
       "      <td>Feb 28, 2020, 12:07pm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3816</th>\n",
       "      <td>https://www.forbes.com/sites/lisettevoytko/202...</td>\n",
       "      <td>9th Person Dies From Coronavirus In Washington...</td>\n",
       "      <td>A stretcher is moved from an ambulance to the ...</td>\n",
       "      <td>38,850</td>\n",
       "      <td>Business</td>\n",
       "      <td>Mar 3, 2020, 03:13pm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3817</th>\n",
       "      <td>https://www.forbes.com/sites/lisettevoytko/202...</td>\n",
       "      <td>Discovery Of 2 Strains Of COVID-19 Coronavirus...</td>\n",
       "      <td>A Centers for Disease Control illustration of ...</td>\n",
       "      <td>124,125</td>\n",
       "      <td>Business</td>\n",
       "      <td>Mar 4, 2020, 12:34pm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3818</th>\n",
       "      <td>https://www.forbes.com/sites/lisettevoytko/202...</td>\n",
       "      <td>DOJ Says Purposefully Spreading Coronavirus Co...</td>\n",
       "      <td>US Attorney General Bill Barr.Topline: The Jus...</td>\n",
       "      <td>9,396</td>\n",
       "      <td>Business</td>\n",
       "      <td>Mar 25, 2020, 11:43am</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1164</th>\n",
       "      <td>https://www.forbes.com/sites/zakdoffman/2020/0...</td>\n",
       "      <td>New Microsoft Security ‘Nightmare’: Users Warn...</td>\n",
       "      <td>SOPA IMAGES/LIGHTROCKET VIA GETTY IMAGESMicros...</td>\n",
       "      <td>60,074</td>\n",
       "      <td>Cybersecurity</td>\n",
       "      <td>Mar 4, 2020, 06:15am</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1165</th>\n",
       "      <td>https://www.forbes.com/sites/zakdoffman/2020/0...</td>\n",
       "      <td>Hackers Attack Microsoft Windows Users: Danger...</td>\n",
       "      <td>GETTYFollowing reports that China has been cau...</td>\n",
       "      <td>11,974</td>\n",
       "      <td>Cybersecurity</td>\n",
       "      <td>Mar 16, 2020, 11:00am</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1166</th>\n",
       "      <td>https://www.forbes.com/sites/zakdoffman/2020/0...</td>\n",
       "      <td>Huawei’s Newest Update—The Ultimate Phone For ...</td>\n",
       "      <td>AFP VIA GETTY IMAGESHuawei has endured a diffi...</td>\n",
       "      <td>356,160</td>\n",
       "      <td>Cybersecurity</td>\n",
       "      <td>Jun 5, 2020, 10:57am</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1167</th>\n",
       "      <td>https://www.forbes.com/sites/zakdoffman/2020/0...</td>\n",
       "      <td>Android Messages And Apple iMessage Beaten By ...</td>\n",
       "      <td>GETTYWhatsApp is on something of a roll at the...</td>\n",
       "      <td>174,791</td>\n",
       "      <td>Cybersecurity</td>\n",
       "      <td>Sep 21, 2020, 07:04pm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1168</th>\n",
       "      <td>https://www.forbes.com/sites/zakdoffman/2020/0...</td>\n",
       "      <td>Huawei Turns To Russia For Its Game-Changing N...</td>\n",
       "      <td>ANTON NOVODEREZHKIN/TASSIt has been clear for ...</td>\n",
       "      <td>25,982</td>\n",
       "      <td>Cybersecurity</td>\n",
       "      <td>Sep 21, 2020, 07:06pm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3741 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   link  \\\n",
       "3814  https://www.forbes.com/sites/lisettevoytko/202...   \n",
       "3815  https://www.forbes.com/sites/lisettevoytko/202...   \n",
       "3816  https://www.forbes.com/sites/lisettevoytko/202...   \n",
       "3817  https://www.forbes.com/sites/lisettevoytko/202...   \n",
       "3818  https://www.forbes.com/sites/lisettevoytko/202...   \n",
       "...                                                 ...   \n",
       "1164  https://www.forbes.com/sites/zakdoffman/2020/0...   \n",
       "1165  https://www.forbes.com/sites/zakdoffman/2020/0...   \n",
       "1166  https://www.forbes.com/sites/zakdoffman/2020/0...   \n",
       "1167  https://www.forbes.com/sites/zakdoffman/2020/0...   \n",
       "1168  https://www.forbes.com/sites/zakdoffman/2020/0...   \n",
       "\n",
       "                                                  title  \\\n",
       "3814  Report: Japan Has No Backup Plan If Olympic Ga...   \n",
       "3815  WHO Raises Coronavirus Threat To ‘Very High’\\u...   \n",
       "3816  9th Person Dies From Coronavirus In Washington...   \n",
       "3817  Discovery Of 2 Strains Of COVID-19 Coronavirus...   \n",
       "3818  DOJ Says Purposefully Spreading Coronavirus Co...   \n",
       "...                                                 ...   \n",
       "1164  New Microsoft Security ‘Nightmare’: Users Warn...   \n",
       "1165  Hackers Attack Microsoft Windows Users: Danger...   \n",
       "1166  Huawei’s Newest Update—The Ultimate Phone For ...   \n",
       "1167  Android Messages And Apple iMessage Beaten By ...   \n",
       "1168  Huawei Turns To Russia For Its Game-Changing N...   \n",
       "\n",
       "                                                   text     view  \\\n",
       "3814  People wearing masks sit in front of a countdo...    6,970   \n",
       "3815  Workers wearing protective gears spray disinfe...    9,653   \n",
       "3816  A stretcher is moved from an ambulance to the ...   38,850   \n",
       "3817  A Centers for Disease Control illustration of ...  124,125   \n",
       "3818  US Attorney General Bill Barr.Topline: The Jus...    9,396   \n",
       "...                                                 ...      ...   \n",
       "1164  SOPA IMAGES/LIGHTROCKET VIA GETTY IMAGESMicros...   60,074   \n",
       "1165  GETTYFollowing reports that China has been cau...   11,974   \n",
       "1166  AFP VIA GETTY IMAGESHuawei has endured a diffi...  356,160   \n",
       "1167  GETTYWhatsApp is on something of a roll at the...  174,791   \n",
       "1168  ANTON NOVODEREZHKIN/TASSIt has been clear for ...   25,982   \n",
       "\n",
       "              topic                    time  \n",
       "3814       Business  Feb 28, 2020, 08:59am   \n",
       "3815       Business  Feb 28, 2020, 12:07pm   \n",
       "3816       Business   Mar 3, 2020, 03:13pm   \n",
       "3817       Business   Mar 4, 2020, 12:34pm   \n",
       "3818       Business  Mar 25, 2020, 11:43am   \n",
       "...             ...                     ...  \n",
       "1164  Cybersecurity   Mar 4, 2020, 06:15am   \n",
       "1165  Cybersecurity  Mar 16, 2020, 11:00am   \n",
       "1166  Cybersecurity   Jun 5, 2020, 10:57am   \n",
       "1167  Cybersecurity  Sep 21, 2020, 07:04pm   \n",
       "1168  Cybersecurity  Sep 21, 2020, 07:06pm   \n",
       "\n",
       "[3741 rows x 6 columns]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# reset index, make sure to print out df to double check the order\n",
    "df = df.reset_index().sort_index()\n",
    "df = df.drop(['index'], axis=1)\n",
    "df.dropna(how='any', inplace=True)\n",
    "\n",
    "# Convert view before getting keyword features\n",
    "df['view'] = df['view'].apply(lambda x: int(x.replace(\",\", \"\").replace(\" \", \"\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df['view'] = df['view'].apply(lambda x: int(x.replace(\",\", \"\").replace(\" \", \"\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Keywords Analysis\n",
    "# Here we use gensim package to extract keyword for every article from its texts\n",
    "lst = []\n",
    "for t in df[\"text\"]:\n",
    "    lst.append(keywords(t).split('\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3734"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_views_count(word):\n",
    "    '''This help function counts the individual views, the total views, total counts, total views / total counts \n",
    "       for every word.\n",
    "    '''\n",
    "    counts = []\n",
    "    for i in range(len(lst)):\n",
    "        text = lst[i]\n",
    "        if word in text:\n",
    "            counts.append(df.iloc[i]['view'])\n",
    "    return (counts, sum(counts), len(counts), sum(counts) / len(counts))\n",
    "\n",
    "def find_max_min_avg(words):\n",
    "    '''This function calculates the 9 keyword features.\n",
    "    '''\n",
    "    # Temp stores the values of total views / total counts for every word in a list of keywords from a given article\n",
    "    temp = [dic[word][3] for word in words]\n",
    "    \n",
    "    # Getting the best, worst and average word\n",
    "    best = np.argmax(temp)\n",
    "    worst = np.argmin(temp)\n",
    "    avg = np.argsort(temp)[len(temp)//2]\n",
    "    \n",
    "    # Getting the individual views for the best, worst and average word\n",
    "    individual_views_worst = dic[words[worst]][0]\n",
    "    individual_views_best = dic[words[best]][0]\n",
    "    individual_views_avg = dic[words[avg]][0]\n",
    "    \n",
    "    # Calculating the features\n",
    "    min_min = min(individual_views_worst)\n",
    "    min_max = max(individual_views_worst)\n",
    "    min_avg = np.mean(individual_views_worst)\n",
    "    max_min = min(individual_views_best)\n",
    "    max_max = max(individual_views_best)\n",
    "    max_avg = np.mean(individual_views_best)\n",
    "    avg_min = min(individual_views_avg)\n",
    "    avg_max = max(individual_views_avg)\n",
    "    avg_avg = np.mean(individual_views_avg)\n",
    "    return [min_min, min_max, min_avg, max_min, max_max, max_avg, avg_min, avg_max, avg_avg]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the big dictionary \n",
    "dic = {}\n",
    "for words in lst:\n",
    "    for word in words:\n",
    "        tup = find_views_count(word)\n",
    "        dic[word] = tup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we invoked the second help function to put the 9 features into a dataframe.\n",
    "kw_df = pd.DataFrame({'kw_min_min' : [],'kw_min_max': [],'kw_min_avg': [],'kw_max_min': [],'kw_max_max': [],'kw_max_avg': [], 'kw_avg_min': [], 'kw_avg_max': [],'kw_avg_avg': []})\n",
    "for words in lst:\n",
    "    row = find_max_min_avg(words)\n",
    "    kw_df.loc[len(kw_df)] = row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combine keywords with entire dataframe\n",
    "df = pd.concat([df,kw_df],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"fixed_other_half7k.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "derrick = pd.read_csv(\"derrick's half.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "for i in df.columns:\n",
    "    print(df[i].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(how='any', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_7k_kw = pd.concat([df,derrick],axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3727"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7460"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3727 +3733"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "for i in fixed_7k_kw.columns:\n",
    "    print(fixed_7k_kw[i].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_7k_kw.to_csv(\"fixed_7k_kw.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7460"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fixed_7k_kw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = fixed_7k_kw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Import different datasets created from data gathering notebook\n",
    "\n",
    "# innovation = pd.read_csv(\"df_innovation_9click.csv\", index_col = 0)\n",
    "# leadership = pd.read_csv(\"df_leadership_9click.csv\", index_col = 0)\n",
    "# lifestyle = pd.read_csv(\"df_lifestyle_9click.csv\", index_col = 0)\n",
    "# small_bus = pd.read_csv(\"df_smallbusiness_9click.csv\", index_col=0)\n",
    "# forbemag = pd.read_csv(\"df_forbesmagazine_9click.csv\", index_col=0)\n",
    "# money = pd.read_csv(\"df_money.csv\", index_col=0) \n",
    "# business = pd.read_csv(\"df_busi_9click.csv\", index_col=0) \n",
    "# wheels = pd.read_csv(\"df_wheels_9click.csv\",  index_col=0)\n",
    "# shopping = pd.read_csv(\"df_shopping_9click.csv\",  index_col=0)\n",
    "# author3 = pd.read_csv(\"df_author3.csv\", index_col=0)\n",
    "# author2 = pd.read_csv(\"df_author2.csv\", index_col=0)\n",
    "\n",
    "\n",
    "archive_7 = pd.read_csv(\"arc_df_7.csv\",\n",
    "                         usecols=[\"link\", \"title\", \"view\", \"topic\", \"text\", \"time\"])\n",
    "\n",
    "\n",
    "archive_6 = pd.read_csv(\"arc_df_6.csv\",\n",
    "                         usecols=[\"link\", \"title\", \"view\", \"topic\", \"text\", \"time\"])\n",
    "\n",
    "archive_5 = pd.read_csv(\"arc_df_5.csv\",\n",
    "                         usecols=[\"link\", \"title\", \"view\", \"topic\", \"text\", \"time\"])\n",
    "\n",
    "archive_4 = pd.read_csv(\"arc_df_4.csv\",\n",
    "                         usecols=[\"link\", \"title\", \"view\", \"topic\", \"text\", \"time\"])\n",
    "archive_3 = pd.read_csv(\"arc_df_3.csv\",\n",
    "                         usecols=[\"link\", \"title\", \"view\", \"topic\", \"text\", \"time\"])\n",
    "archive_2 = pd.read_csv(\"arc_df_2.csv\",\n",
    "                    usecols=[\"link\", \"title\", \"view\", \"topic\", \"text\", \"time\"])\n",
    "archive = pd.read_csv(\"arc_df.csv\",\n",
    "                    usecols=[\"link\", \"title\", \"view\", \"topic\", \"text\", \"time\"])\n",
    "data_1_read = pd.read_csv(\"data_1.csv\",\n",
    "                            usecols=[\"link\", \"title\", \"view\", \"topic\", \"text\", \"time\"])\n",
    "now_num_img_rest = pd.read_csv(\"now_num_img_rest.csv\",\n",
    "                               usecols=[\"link\", \"title\", \"view\", \"topic\", \"text\", \"time\"])\n",
    "topics_num_img = pd.read_csv(\"dfs_sub_w_im.csv\", \n",
    "                             usecols=[\"link\", \"title\", \"view\", \"topic\", \"text\", \"time\"])\n",
    "main_num_img = pd.read_csv(\"dfs_main_w_img.csv\", \n",
    "                             usecols=[\"link\", \"title\", \"view\", \"topic\", \"text\", \"time\"])\n",
    "now_num_37 = pd.read_csv(\"now_num_37.csv\", \n",
    "                             usecols=[\"link\", \"title\", \"view\", \"topic\", \"text\", \"time\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with_img = pd.concat([data_1_read, topics_num_img, main_num_img,\n",
    "                      #now_num_37,now_num_img_rest, archive, archive_2,\n",
    "                    # archive_3,archive_4, archive_5], ignore_index=False)\n",
    "\n",
    "with_img = pd.concat([data_reimport, archive_6, archive_7],ignore_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_img = clean(with_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_img = with_img.drop_duplicates(subset='title', keep='last')\n",
    "with_img = with_img.drop_duplicates(subset='link', keep='last')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fixing Haleys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data_reimport = pd.read_csv(\"Features.csv\", index_col= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [],
   "source": [
    "df =  data_reimport.reset_index().sort_index() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['index', 'Unnamed: 0.1', 'link', 'title', 'text', 'view', 'topic',\n",
       "       'time', 'month', 'Innovation', 'Leadership', 'Lifestyle', 'Money',\n",
       "       'Unnamed: 13', 'Apr', 'Aug', 'Dec', 'Feb', 'Jan', 'Jul', 'Jun', 'Mar',\n",
       "       'May', 'Nov', 'Oct', 'Sep', 'n_tokens_title:', 'n_tokens_content',\n",
       "       'n_unique_tokens', 'average_token_length', 'n_non_stop_words',\n",
       "       'n_non_stop_unique_tokens', 'day_of_week', 'friday', 'monday',\n",
       "       'saturday', 'sunday', 'thursday', 'tuesday', 'wednesday',\n",
       "       'weekend_or_weekday', 'weekday', 'weekend', 'global_sentiment_polarity',\n",
       "       'global_subjectivity', 'title_sentiment_polarity',\n",
       "       'abs_title_sentiment_polarity', 'title_subjectivity',\n",
       "       'abs_title_subjectivity', 'global_rate_positive_words',\n",
       "       'global_rate_negative_words', 'rate_positive_words',\n",
       "       'rate_negative_words', 'avg_positive_polarity', 'min_positive_polarity',\n",
       "       'max_positive_polarity', 'avg_negative_polarity',\n",
       "       'min_negative_polarity', 'max_negative_polarity', 'LDA_00', 'LDA_01',\n",
       "       'LDA_02', 'LDA_03', 'LDA_04', 'timedelta', 'num_keywords'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 428,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['index', 'Unnamed: 0.1', 'Unnamed: 13'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "link\n",
      "0\n",
      "title\n",
      "0\n",
      "text\n",
      "0\n",
      "view\n",
      "0\n",
      "topic\n",
      "0\n",
      "time\n",
      "0\n",
      "month\n",
      "0\n",
      "Innovation\n",
      "0\n",
      "Leadership\n",
      "0\n",
      "Lifestyle\n",
      "0\n",
      "Money\n",
      "0\n",
      "Apr\n",
      "0\n",
      "Aug\n",
      "0\n",
      "Dec\n",
      "0\n",
      "Feb\n",
      "0\n",
      "Jan\n",
      "0\n",
      "Jul\n",
      "0\n",
      "Jun\n",
      "0\n",
      "Mar\n",
      "0\n",
      "May\n",
      "0\n",
      "Nov\n",
      "0\n",
      "Oct\n",
      "0\n",
      "Sep\n",
      "0\n",
      "n_tokens_title:\n",
      "0\n",
      "n_tokens_content\n",
      "0\n",
      "n_unique_tokens\n",
      "0\n",
      "average_token_length\n",
      "0\n",
      "n_non_stop_words\n",
      "0\n",
      "n_non_stop_unique_tokens\n",
      "0\n",
      "day_of_week\n",
      "0\n",
      "friday\n",
      "0\n",
      "monday\n",
      "0\n",
      "saturday\n",
      "0\n",
      "sunday\n",
      "0\n",
      "thursday\n",
      "0\n",
      "tuesday\n",
      "0\n",
      "wednesday\n",
      "0\n",
      "weekend_or_weekday\n",
      "0\n",
      "weekday\n",
      "0\n",
      "weekend\n",
      "0\n",
      "global_sentiment_polarity\n",
      "0\n",
      "global_subjectivity\n",
      "0\n",
      "title_sentiment_polarity\n",
      "0\n",
      "abs_title_sentiment_polarity\n",
      "0\n",
      "title_subjectivity\n",
      "0\n",
      "abs_title_subjectivity\n",
      "0\n",
      "global_rate_positive_words\n",
      "0\n",
      "global_rate_negative_words\n",
      "0\n",
      "rate_positive_words\n",
      "0\n",
      "rate_negative_words\n",
      "0\n",
      "avg_positive_polarity\n",
      "0\n",
      "min_positive_polarity\n",
      "0\n",
      "max_positive_polarity\n",
      "0\n",
      "avg_negative_polarity\n",
      "0\n",
      "min_negative_polarity\n",
      "0\n",
      "max_negative_polarity\n",
      "0\n",
      "LDA_00\n",
      "0\n",
      "LDA_01\n",
      "0\n",
      "LDA_02\n",
      "0\n",
      "LDA_03\n",
      "0\n",
      "LDA_04\n",
      "0\n",
      "timedelta\n",
      "0\n",
      "num_keywords\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "for index, i in enumerate(df.columns):\n",
    "    print(df.columns[index])\n",
    "    print(df[i].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = {}\n",
    "for i in range(len(df)):\n",
    "    date = datetime.datetime.strptime(df['time'][i].replace(\" \", \"\"), \"%b%d,%Y,%I:%M%p\")\n",
    "    month = date.month\n",
    "    if month in dic:\n",
    "        dic[month] += 1\n",
    "    else:\n",
    "        dic[month] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([(1, 577),\n",
       "             (2, 512),\n",
       "             (3, 577),\n",
       "             (4, 446),\n",
       "             (5, 672),\n",
       "             (6, 485),\n",
       "             (7, 551),\n",
       "             (8, 583),\n",
       "             (9, 671),\n",
       "             (10, 414),\n",
       "             (11, 1481),\n",
       "             (12, 497)])"
      ]
     },
     "execution_count": 432,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "OrderedDict(sorted(dic.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0]"
      ]
     },
     "execution_count": 433,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Haley's feature engineering:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['link', 'title', 'text', 'view', 'topic', 'time', 'month', 'Innovation',\n",
       "       'Leadership', 'Lifestyle', 'Money', 'Apr', 'Aug', 'Dec', 'Feb', 'Jan',\n",
       "       'Jul', 'Jun', 'Mar', 'May', 'Nov', 'Oct', 'Sep', 'n_tokens_title:',\n",
       "       'n_tokens_content', 'n_unique_tokens', 'average_token_length',\n",
       "       'n_non_stop_words', 'n_non_stop_unique_tokens', 'day_of_week', 'friday',\n",
       "       'monday', 'saturday', 'sunday', 'thursday', 'tuesday', 'wednesday',\n",
       "       'weekend_or_weekday', 'weekday', 'weekend', 'global_sentiment_polarity',\n",
       "       'global_subjectivity', 'title_sentiment_polarity',\n",
       "       'abs_title_sentiment_polarity', 'title_subjectivity',\n",
       "       'abs_title_subjectivity', 'global_rate_positive_words',\n",
       "       'global_rate_negative_words', 'rate_positive_words',\n",
       "       'rate_negative_words', 'avg_positive_polarity', 'min_positive_polarity',\n",
       "       'max_positive_polarity', 'avg_negative_polarity',\n",
       "       'min_negative_polarity', 'max_negative_polarity', 'LDA_00', 'LDA_01',\n",
       "       'LDA_02', 'LDA_03', 'LDA_04', 'timedelta', 'num_keywords'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 434,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7466"
      ]
     },
     "execution_count": 435,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates(subset='title', keep='last')\n",
    "df = df.drop_duplicates(subset='link', keep='last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7466"
      ]
     },
     "execution_count": 437,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7466"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_derrick = pd.read_csv(\"derrick's half.csv\", index_col = 0) \n",
    "df_alice = pd.read_csv(\"fixed_other_half7k.csv\", index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2 = pd.concat([df_derrick,df_alice], axis=0)\n",
    "df_2.dropna(how='any', inplace=True)\n",
    "df_2 = df_2.reset_index().sort_index()\n",
    "df_2 = df_2.drop(['index'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7460"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2 = df_2.drop_duplicates(subset='title', keep='last')\n",
    "df_2 = df_2.drop_duplicates(subset='link', keep='last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7460"
      ]
     },
     "execution_count": 441,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.merge(df, df_2, on=['link', 'title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7456"
      ]
     },
     "execution_count": 443,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = result.drop_duplicates(subset='title', keep='last')\n",
    "result = result.drop_duplicates(subset='link', keep='last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7456"
      ]
     },
     "execution_count": 445,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "link\n",
      "0\n",
      "title\n",
      "0\n",
      "text_x\n",
      "0\n",
      "view_x\n",
      "0\n",
      "topic_x\n",
      "0\n",
      "time_x\n",
      "0\n",
      "month\n",
      "0\n",
      "Innovation\n",
      "0\n",
      "Leadership\n",
      "0\n",
      "Lifestyle\n",
      "0\n",
      "Money\n",
      "0\n",
      "Apr\n",
      "0\n",
      "Aug\n",
      "0\n",
      "Dec\n",
      "0\n",
      "Feb\n",
      "0\n",
      "Jan\n",
      "0\n",
      "Jul\n",
      "0\n",
      "Jun\n",
      "0\n",
      "Mar\n",
      "0\n",
      "May\n",
      "0\n",
      "Nov\n",
      "0\n",
      "Oct\n",
      "0\n",
      "Sep\n",
      "0\n",
      "n_tokens_title:\n",
      "0\n",
      "n_tokens_content\n",
      "0\n",
      "n_unique_tokens\n",
      "0\n",
      "average_token_length\n",
      "0\n",
      "n_non_stop_words\n",
      "0\n",
      "n_non_stop_unique_tokens\n",
      "0\n",
      "day_of_week\n",
      "0\n",
      "friday\n",
      "0\n",
      "monday\n",
      "0\n",
      "saturday\n",
      "0\n",
      "sunday\n",
      "0\n",
      "thursday\n",
      "0\n",
      "tuesday\n",
      "0\n",
      "wednesday\n",
      "0\n",
      "weekend_or_weekday\n",
      "0\n",
      "weekday\n",
      "0\n",
      "weekend\n",
      "0\n",
      "global_sentiment_polarity\n",
      "0\n",
      "global_subjectivity\n",
      "0\n",
      "title_sentiment_polarity\n",
      "0\n",
      "abs_title_sentiment_polarity\n",
      "0\n",
      "title_subjectivity\n",
      "0\n",
      "abs_title_subjectivity\n",
      "0\n",
      "global_rate_positive_words\n",
      "0\n",
      "global_rate_negative_words\n",
      "0\n",
      "rate_positive_words\n",
      "0\n",
      "rate_negative_words\n",
      "0\n",
      "avg_positive_polarity\n",
      "0\n",
      "min_positive_polarity\n",
      "0\n",
      "max_positive_polarity\n",
      "0\n",
      "avg_negative_polarity\n",
      "0\n",
      "min_negative_polarity\n",
      "0\n",
      "max_negative_polarity\n",
      "0\n",
      "LDA_00\n",
      "0\n",
      "LDA_01\n",
      "0\n",
      "LDA_02\n",
      "0\n",
      "LDA_03\n",
      "0\n",
      "LDA_04\n",
      "0\n",
      "timedelta\n",
      "0\n",
      "num_keywords\n",
      "0\n",
      "text_y\n",
      "0\n",
      "view_y\n",
      "0\n",
      "topic_y\n",
      "0\n",
      "time_y\n",
      "0\n",
      "kw_min_min\n",
      "0\n",
      "kw_min_max\n",
      "0\n",
      "kw_min_avg\n",
      "0\n",
      "kw_max_min\n",
      "0\n",
      "kw_max_max\n",
      "0\n",
      "kw_max_avg\n",
      "0\n",
      "kw_avg_min\n",
      "0\n",
      "kw_avg_max\n",
      "0\n",
      "kw_avg_avg\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "for index, i in enumerate(result.columns):\n",
    "    print(result.columns[index])\n",
    "    print(result[i].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.dropna(how='any', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7456"
      ]
     },
     "execution_count": 448,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['link', 'title', 'text_x', 'view_x', 'topic_x', 'time_x', 'month',\n",
       "       'Innovation', 'Leadership', 'Lifestyle', 'Money', 'Apr', 'Aug', 'Dec',\n",
       "       'Feb', 'Jan', 'Jul', 'Jun', 'Mar', 'May', 'Nov', 'Oct', 'Sep',\n",
       "       'n_tokens_title:', 'n_tokens_content', 'n_unique_tokens',\n",
       "       'average_token_length', 'n_non_stop_words', 'n_non_stop_unique_tokens',\n",
       "       'day_of_week', 'friday', 'monday', 'saturday', 'sunday', 'thursday',\n",
       "       'tuesday', 'wednesday', 'weekend_or_weekday', 'weekday', 'weekend',\n",
       "       'global_sentiment_polarity', 'global_subjectivity',\n",
       "       'title_sentiment_polarity', 'abs_title_sentiment_polarity',\n",
       "       'title_subjectivity', 'abs_title_subjectivity',\n",
       "       'global_rate_positive_words', 'global_rate_negative_words',\n",
       "       'rate_positive_words', 'rate_negative_words', 'avg_positive_polarity',\n",
       "       'min_positive_polarity', 'max_positive_polarity',\n",
       "       'avg_negative_polarity', 'min_negative_polarity',\n",
       "       'max_negative_polarity', 'LDA_00', 'LDA_01', 'LDA_02', 'LDA_03',\n",
       "       'LDA_04', 'timedelta', 'num_keywords', 'text_y', 'view_y', 'topic_y',\n",
       "       'time_y', 'kw_min_min', 'kw_min_max', 'kw_min_avg', 'kw_max_min',\n",
       "       'kw_max_max', 'kw_max_avg', 'kw_avg_min', 'kw_avg_max', 'kw_avg_avg'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 449,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_2 = result.drop(['text_y', 'view_y', 'topic_y','time_y'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_2 = result_2.rename(columns={'text_x': 'text', 'view_x': 'view', 'topic_x': 'topic', 'time_x':'time'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['link', 'title', 'text', 'view', 'topic', 'time', 'month', 'Innovation',\n",
       "       'Leadership', 'Lifestyle', 'Money', 'Apr', 'Aug', 'Dec', 'Feb', 'Jan',\n",
       "       'Jul', 'Jun', 'Mar', 'May', 'Nov', 'Oct', 'Sep', 'n_tokens_title:',\n",
       "       'n_tokens_content', 'n_unique_tokens', 'average_token_length',\n",
       "       'n_non_stop_words', 'n_non_stop_unique_tokens', 'day_of_week', 'friday',\n",
       "       'monday', 'saturday', 'sunday', 'thursday', 'tuesday', 'wednesday',\n",
       "       'weekend_or_weekday', 'weekday', 'weekend', 'global_sentiment_polarity',\n",
       "       'global_subjectivity', 'title_sentiment_polarity',\n",
       "       'abs_title_sentiment_polarity', 'title_subjectivity',\n",
       "       'abs_title_subjectivity', 'global_rate_positive_words',\n",
       "       'global_rate_negative_words', 'rate_positive_words',\n",
       "       'rate_negative_words', 'avg_positive_polarity', 'min_positive_polarity',\n",
       "       'max_positive_polarity', 'avg_negative_polarity',\n",
       "       'min_negative_polarity', 'max_negative_polarity', 'LDA_00', 'LDA_01',\n",
       "       'LDA_02', 'LDA_03', 'LDA_04', 'timedelta', 'num_keywords', 'kw_min_min',\n",
       "       'kw_min_max', 'kw_min_avg', 'kw_max_min', 'kw_max_max', 'kw_max_avg',\n",
       "       'kw_avg_min', 'kw_avg_max', 'kw_avg_avg'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 452,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_2.to_csv(\"FIXED_7k.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0]"
      ]
     },
     "execution_count": 453,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(result_2.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1481"
      ]
     },
     "execution_count": 454,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result_2[result_2.month == 'Nov'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = {}\n",
    "for i in range(len(result_2)):\n",
    "    date = datetime.datetime.strptime(result_2['time'][i].replace(\" \", \"\"), \"%b%d,%Y,%I:%M%p\")\n",
    "    month = date.month\n",
    "    if month in dic:\n",
    "        dic[month] += 1\n",
    "    else:\n",
    "        dic[month] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([(1, 576),\n",
       "             (2, 509),\n",
       "             (3, 575),\n",
       "             (4, 446),\n",
       "             (5, 672),\n",
       "             (6, 483),\n",
       "             (7, 551),\n",
       "             (8, 583),\n",
       "             (9, 669),\n",
       "             (10, 414),\n",
       "             (11, 1481),\n",
       "             (12, 497)])"
      ]
     },
     "execution_count": 456,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "OrderedDict(sorted(dic.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
